{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74d02115",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21e2190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import math\n",
    "import scipy as sp\n",
    "import PIL\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow.keras import models, layers, Model\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, ZeroPadding2D\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications import EfficientNetB3, ResNet50V2, DenseNet121, VGG19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6529e76e",
   "metadata": {},
   "source": [
    "# Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25f66d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CurrentDirectory = \"./\"\n",
    "\n",
    "train_directory = CurrentDirectory + 'train/'\n",
    "test_directory  = CurrentDirectory + 'test/'\n",
    "model_directory = CurrentDirectory + 'model/'\n",
    "tensorboard_directory = CurrentDirectory + 'Tensorboard'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b29b36",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04cd1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size: 한번에 forward & Backword 하는 샘플의 수\n",
    "batch_size = 64\n",
    "\n",
    "# Epochs 수\n",
    "epochs = 50\n",
    "\n",
    "# Weight 조절 parameter\n",
    "LearningRate = 1e-3 # 0.001\n",
    "Decay = 1e-6\n",
    "\n",
    "# 이미지 데이터 입력값\n",
    "img_width = 224\n",
    "img_height = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcb89af",
   "metadata": {},
   "source": [
    "# ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f715339e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 도중 이미지 임의 변형 및 정규화 적용 가능\n",
    "# 1. 이미지를 전부다 불러서 램 (메모리)에 올릴 수 없기 때문\n",
    "# 2. 이미지는 Augmentation을 해주는게 좋아서\n",
    "DATAGEN_TRAIN = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    data_format=\"channels_last\",\n",
    "    validation_split=0.10) # Train / Validation\n",
    "\n",
    "# Test 데이터에는 Augmentation 적용하지 않음\n",
    "DATAGEN_TEST = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    data_format=\"channels_last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08259fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow_from_directory - 이미지가 폴더별로 분류되어 있을 경우 subdirectory 이름에 맞춰 자동으로 target class 만듦\n",
    "# Generator의 instance 생성 (Train)\n",
    "TRAIN_GENERATOR = DATAGEN_TRAIN.flow_from_directory(\n",
    "    train_directory,\n",
    "    target_size = (img_width, img_height),\n",
    "    batch_size = batch_size,\n",
    "    class_mode= \"categorical\",\n",
    "    subset = \"training\")\n",
    "\n",
    "VALID_GENERATOR = DATAGEN_TRAIN.flow_from_directory(\n",
    "    train_directory,\n",
    "    target_size = (img_width, img_height),\n",
    "    batch_size = batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    subset = \"validation\")\n",
    "\n",
    "# Generator의 instance 생성 (Test)\n",
    "TEST_GENERATOR = DATAGEN_TEST.flow_from_directory(\n",
    "    test_directory,\n",
    "    target_size = (img_width, img_height),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3a9fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALID_GENERATOR가 target class 모두 포함하는지 확인\n",
    "len(pd.Series( VALID_GENERATOR.labels ).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b5df78",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf183de6",
   "metadata": {},
   "source": [
    "#### Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b498ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call-back 함수\n",
    "# CheckPoint: Epoch 마다 val_loss를 확인하여, 값이 향상되었을 경우에만 저장\n",
    "CP = ModelCheckpoint(filepath=model_directory+'Efnet-{epoch:03d}-{val_loss:.4f}-{val_acc:.4f}.hdf5',\n",
    "            monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "# 학습과정 진행사항 확인\n",
    "TB = TensorBoard(log_dir=tensorboard_directory, write_graph=True, write_images=True)\n",
    "\n",
    "# 모델의 개선이 없을 경우 Learning rate 조절\n",
    "LR = ReduceLROnPlateau(monitor='val_loss',factor=0.8,patience=3, verbose=1, min_lr=1e-7)\n",
    "\n",
    "CALLBACK = [CP, TB, LR]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fce6a5a",
   "metadata": {},
   "source": [
    "## EfficientNetB3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1922e0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_1 = tf.keras.applications.efficientnet.EfficientNetB3(\n",
    "    include_top=None,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=(img_width,img_height,3),\n",
    "    pooling=None)\n",
    "\n",
    "x = GlobalAveragePooling2D()(Model_1.output)\n",
    "predictions = Dense(88, activation='softmax')(x)\n",
    "\n",
    "Efnet = Model(inputs=Model_1.input, outputs=predictions)\n",
    "\n",
    "# learning parameter를 더하여 최종 model compile\n",
    "Efnet.compile(optimizer=\n",
    "         SGD(learning_rate=LearningRate, decay=Decay, momentum=0.9, nesterov=True), \n",
    "         loss='categorical_crossentropy',\n",
    "         metrics=['acc'])\n",
    "\n",
    "# Training Start\n",
    "Efnet.fit(\n",
    "        TRAIN_GENERATOR,\n",
    "        # 데이터가 너무 클 경우 1-epoch을 못하는 경우\n",
    "        # steps_per_epoch=TRAIN_GENERATOR.n / batch_size,\n",
    "        epochs=epochs,\n",
    "        callbacks=CALLBACK,\n",
    "        shuffle=True, # Training에 패턴이 존재하면 overfit이 잘 되기 때문에, Shuffle 사용해야함. 단 test에는 절대 X\n",
    "        validation_data=VALID_GENERATOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2debd36b",
   "metadata": {},
   "source": [
    "### ResNet50V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3f041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_2 = tf.keras.applications.ResNet50V2(\n",
    "    include_top=None,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=(img_width,img_height,3),\n",
    "    pooling=None)\n",
    "\n",
    "x = GlobalAveragePooling2D()(Model_2.output)\n",
    "predictions = Dense(88, activation='softmax')(x)\n",
    "\n",
    "Resnet = Model(inputs=Model_2.input, outputs=predictions)\n",
    "\n",
    "# learning parameter를 더하여 최종 model compile\n",
    "Resnet.compile(optimizer=\n",
    "         SGD(learning_rate=LearningRate, decay=Decay, momentum=0.9, nesterov=True), \n",
    "         loss='categorical_crossentropy',\n",
    "         metrics=['acc'])\n",
    "\n",
    "# Training Start\n",
    "Resnet.fit(\n",
    "        TRAIN_GENERATOR,\n",
    "        # 데이터가 너무 클 경우 1-epoch을 못하는 경우\n",
    "        # steps_per_epoch=TRAIN_GENERATOR.n / batch_size,\n",
    "        epochs=epochs,\n",
    "        callbacks=CALLBACK,\n",
    "        shuffle=True, # Training에 패턴이 존재하면 overfit이 잘 되기 때문에, Shuffle 사용해야함. 단 test에는 절대 X\n",
    "        validation_data=VALID_GENERATOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2383752",
   "metadata": {},
   "source": [
    "### DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76e786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_3 = tf.keras.applications.DenseNet121(\n",
    "    include_top=None,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=(img_width,img_height,3),\n",
    "    pooling=None)\n",
    "\n",
    "x = GlobalAveragePooling2D()(Model_3.output)\n",
    "predictions = Dense(88, activation='softmax')(x)\n",
    "\n",
    "Dsnet = Model(inputs=Model_3.input, outputs=predictions)\n",
    "\n",
    "# learning parameter를 더하여 최종 model compile\n",
    "Dsnet.compile(optimizer=\n",
    "         SGD(learning_rate=LearningRate, decay=Decay, momentum=0.9, nesterov=True), \n",
    "         loss='categorical_crossentropy',\n",
    "         metrics=['acc'])\n",
    "\n",
    "# Training Start\n",
    "Dsnet.fit(\n",
    "        TRAIN_GENERATOR,\n",
    "        # 데이터가 너무 클 경우 1-epoch을 못하는 경우\n",
    "        # steps_per_epoch=TRAIN_GENERATOR.n / batch_size,\n",
    "        epochs=epochs,\n",
    "        callbacks=CALLBACK,\n",
    "        shuffle=True, # Training에 패턴이 존재하면 overfit이 잘 되기 때문에, Shuffle 사용해야함. 단 test에는 절대 X\n",
    "        validation_data=VALID_GENERATOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deb56ef",
   "metadata": {},
   "source": [
    "### VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3622dc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_4 = tf.keras.applications.VGG19(\n",
    "    include_top=None,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=(img_width,img_height,3),\n",
    "    pooling=None)\n",
    "\n",
    "x = GlobalAveragePooling2D()(Model_4.output)\n",
    "predictions = Dense(88, activation='softmax')(x)\n",
    "\n",
    "Vgg19 = Model(inputs=Model_4.input, outputs=predictions)\n",
    "\n",
    "# learning parameter를 더하여 최종 model compile\n",
    "Vgg19.compile(optimizer=\n",
    "         SGD(learning_rate=LearningRate, decay=Decay, momentum=0.9, nesterov=True), \n",
    "         loss='categorical_crossentropy',\n",
    "         metrics=['acc'])\n",
    "\n",
    "# Training Start\n",
    "Vgg19.fit(\n",
    "        TRAIN_GENERATOR,\n",
    "        # 데이터가 너무 클 경우 1-epoch을 못하는 경우\n",
    "        # steps_per_epoch=TRAIN_GENERATOR.n / batch_size,\n",
    "        epochs=epochs,\n",
    "        callbacks=CALLBACK,\n",
    "        shuffle=True, # Training에 패턴이 존재하면 overfit이 잘 되기 때문에, Shuffle 사용해야함. 단 test에는 절대 X\n",
    "        validation_data=VALID_GENERATOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52cb79f",
   "metadata": {},
   "source": [
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d868373f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_Efnet = Efnet.predict_generator(TEST_GENERATOR, verbose=1)\n",
    "prediction_Resnet = Resnet.predict_generator(TEST_GENERATOR, verbose=1)\n",
    "prediction_Dsnet = Dsnet.predict_generator(TEST_GENERATOR, verbose=1)\n",
    "prediction_Vgg19 = Vgg19.predict_generator(TEST_GENERATOR, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a15655",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d438b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = pd.read_csv(\"train_df.csv\")\n",
    "\n",
    "train_labels = train_y[\"label\"]\n",
    "\n",
    "label_unique = sorted(np.unique(train_labels))\n",
    "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
    "\n",
    "train_labels = [label_unique[k] for k in train_labels]\n",
    "\n",
    "label_decoder = {val:key for key, val in label_unique.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90d2089",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_pred = []\n",
    "\n",
    "# 모델에 맞게 prediction 값 변경\n",
    "for i in range(len(prediction)):\n",
    "    f_pred.append(prediction[i].argmax())\n",
    "    \n",
    "f_result = [label_decoder[result] for result in f_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b2a561",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "submission[\"label\"] = f_result\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
